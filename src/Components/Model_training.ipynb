{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END to END DL Project using Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb    ## importing imdb dataset from keras\n",
    "from tensorflow.keras.preprocessing import sequence  # a sequence refers to an ordered collection of items, \n",
    "                                                    # which could be numbers, words, or other types of data that are arranged in a specific order.\n",
    "from tensorflow.keras.models import Sequential   ## The Sequential model is one of the simplest ways to create a neural network, \n",
    "                                                  # where you can add layers one after the other in a sequential manner.\n",
    "# A recurrent layer is a type of layer in neural networks specifically designed to handle sequential data.\n",
    "# SimpleRNN is a type of recurrent layer that is designed for sequential data, such as time series or natural language.\n",
    "# The Embedding layer is used to convert integer-encoded words into dense vectors of fixed size. It is typically used in natural language processing (NLP) tasks.\n",
    "# The Dense layer is a fully connected neural network layer where each neuron is connected to every neuron in the previous layer.\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the Imdb dataset\n",
    "\n",
    "max_features=10000\n",
    "(X_train, y_train),(X_test, y_test)= imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect a sample review and its label \n",
    "\n",
    "Sample_review=X_train[0]\n",
    "Sample_label=y_train[0]\n",
    "print(f'Sample Review (as integers) :{Sample_review}')\n",
    "print(f'Sample label :{Sample_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mapping of indexes in review back to words for our better understanding\n",
    "\n",
    "word_index=imdb.get_word_index()\n",
    "reverse_word_index={value : key for key, value in word_index.items()}\n",
    "reverse_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## decoding the review to get the first sentence review in text format\n",
    "\n",
    "decoded_review = ' '.join([reverse_word_index.get(i -3, '?') for i in Sample_review])\n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "max_len=350\n",
    "\n",
    "X_train=sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test=sequence.pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "import numpy as np\n",
    "\n",
    "# Define parameters\n",
    "max_features = 10000  # Vocabulary size\n",
    "embedding_dim = 128   # Dimension of embedding space\n",
    "max_len = 350         # Length of each input sequence\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim))  # Removed input_length\n",
    "model.add(SimpleRNN(128, activation='relu'))  # 128 neurons in RNN layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Use a dummy input to force the model to build and display the summary\n",
    "dummy_input = np.zeros((1, max_len), dtype=np.int32)  # Batch size of 1, with sequence length max_len\n",
    "model(dummy_input)  # Pass dummy input to the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an instance of early stopping call back \n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping=EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train the model with earlystopping \n",
    "\n",
    "history=model.fit(\n",
    "  X_train,y_train, epochs=10, batch_size=32,\n",
    "  validation_split=0.2,\n",
    "  callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"RNN_Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"RNN_Model.keras\") ## Saving the model in keras format \n",
    "\n",
    "# example:\n",
    "#  e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
